{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress:\n",
    "1. Split the whole original dataset (9,000) images into train (80%), val (10%), test (10%)\n",
    "2. Downsize Wildlife_Animals_Split --> Wildlife_Animals_Downsized: train (1000 images), val (20%), test (20%)\n",
    "3. Create ground truth labels (.txt files) for the Dataset_Downsized images and place inside ./Wildlife_Animals_Downsized/labels\n",
    "4. Create data.yaml file for yolov8 model\n",
    "\n",
    "### TO-DO: \n",
    "1. Train model and run inference to gather annotated images + .txt files\n",
    "2. Pass validation data and run inference to gather annotated images + .txt files. If predicted boxes and is classified well, move on\n",
    "3. Pass test data and run inference to gather annoted images + .txt files. This set is used for the professor to run but double check to see if model runs good on unseen data\n",
    "4. Figure out way that once the animal is classified, return is animal is harmful or harmless. Probably hardcode this and use a mapping\n",
    "5. Export model and logic and figure out android simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow:\n",
    "1. Generate ground truth labels for the downsized dataset: train, val, test\n",
    "2. Train the model on training set. Run inference on the training set to manually view how well the model detected and classified the animal in the image. Hypertune parameters if needed\n",
    "3. Validate model by passing validation data to model. Evaluate the Precision, Recall, F1-Score, mAP, IoU. Run inference on validation data to view how well model detected and classified on unseen data. Hypertune paramters if needed\n",
    "4. Test the model by passing testing data to model. Evaluate the Precision, Recall, F1-Score, mAP, IoU. Run inference on test data to view how well model detected and classified on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ultralytics import YOLO\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do not need to run. Check below for starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting into train, val, test and downsizing to train (1000 images), val (20%), test(20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing class folders\n",
    "dataset_path = './CMPE258_Wildlife_Animals/Dataset'\n",
    "output_path = './CMPE258_Wildlife_Animals/Wildlife_Animals_Split/images'\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split into train, validation, and test complete!\n"
     ]
    }
   ],
   "source": [
    "# split original dataset into 80-10-10 : train, val, test\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ratios for train, validation, and test sets\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.10\n",
    "test_ratio = 0.10\n",
    "\n",
    "# Create train, val, and test directories\n",
    "train_dir = os.path.join(output_path, 'train')\n",
    "val_dir = os.path.join(output_path, 'val')\n",
    "test_dir = os.path.join(output_path, 'test')\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Split each class folder\n",
    "for class_name in os.listdir(dataset_path):\n",
    "    class_path = os.path.join(dataset_path, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    # Get all image file paths\n",
    "    images = [os.path.join(class_path, img) for img in os.listdir(class_path) if img.endswith(('jpg', 'jpeg', 'png'))]\n",
    "\n",
    "    # First split into train and temp (validation + test)\n",
    "    train_images, temp_images = train_test_split(images, test_size=(val_ratio + test_ratio), random_state=42)\n",
    "    # Then split temp into validation and test sets\n",
    "    val_images, test_images = train_test_split(temp_images, test_size=test_ratio / (val_ratio + test_ratio), random_state=42)\n",
    "\n",
    "    # Create class directories in train, val, and test\n",
    "    train_class_dir = os.path.join(train_dir, class_name)\n",
    "    val_class_dir = os.path.join(val_dir, class_name)\n",
    "    test_class_dir = os.path.join(test_dir, class_name)\n",
    "    os.makedirs(train_class_dir, exist_ok=True)\n",
    "    os.makedirs(val_class_dir, exist_ok=True)\n",
    "    os.makedirs(test_class_dir, exist_ok=True)\n",
    "\n",
    "    # Move images to respective directories\n",
    "    for img in train_images:\n",
    "        shutil.copy(img, train_class_dir)\n",
    "    for img in val_images:\n",
    "        shutil.copy(img, val_class_dir)\n",
    "    for img in test_images:\n",
    "        shutil.copy(img, test_class_dir)\n",
    "\n",
    "print(\"Dataset split into train, validation, and test complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsize training set to 1000 images only\n",
    "\n",
    "# Define paths\n",
    "parent_dir = './Wildlife_Animals_Split/images/train'\n",
    "\n",
    "# Collect all valid image paths\n",
    "image_files = []\n",
    "for class_name in os.listdir(parent_dir):\n",
    "    class_path = os.path.join(parent_dir, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "    for img_name in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        if img_path.lower().endswith(('jpg', 'jpeg', 'png')):\n",
    "            image_files.append(img_path)\n",
    "\n",
    "# Randomly select 1,000 images\n",
    "selected_images = random.sample(image_files, 1000)\n",
    "\n",
    "# Clear the existing train folder and downsized dataset folder\n",
    "downsized_images_dir = './Wildlife_Animals_Downsized/images/train'\n",
    "os.makedirs(downsized_images_dir, exist_ok=True)\n",
    "\n",
    "# Move selected images and their labels to downsized dataset\n",
    "for img_path in selected_images:\n",
    "    img_name = os.path.basename(img_path)\n",
    "    class_name = os.path.basename(os.path.dirname(img_path))\n",
    "\n",
    "    # Create class directories\n",
    "    os.makedirs(os.path.join(downsized_images_dir, class_name), exist_ok=True)\n",
    "\n",
    "    # Move image\n",
    "    shutil.copy(img_path, os.path.join(downsized_images_dir, class_name, img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsize validation set to take 20% of original validation set\n",
    "\n",
    "# Define paths\n",
    "parent_dir = './Wildlife_Animals_Split/images/val'\n",
    "\n",
    "# Collect all valid image paths\n",
    "image_files = []\n",
    "for class_name in os.listdir(parent_dir):\n",
    "    class_path = os.path.join(parent_dir, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "    for img_name in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        if img_path.lower().endswith(('jpg', 'jpeg', 'png')):\n",
    "            image_files.append(img_path)\n",
    "\n",
    "\n",
    "subset_size = int(0.2 * len(image_files))  # 20% of the original validation set\n",
    "selected_images = random.sample(image_files, subset_size)\n",
    "\n",
    "# Clear the existing train folder and downsized dataset folder\n",
    "downsized_images_dir = './Wildlife_Animals_Downsized/images/val'\n",
    "os.makedirs(downsized_images_dir, exist_ok=True)\n",
    "\n",
    "# Move selected images and their labels to downsized dataset\n",
    "for img_path in selected_images:\n",
    "    img_name = os.path.basename(img_path)\n",
    "    class_name = os.path.basename(os.path.dirname(img_path))\n",
    "\n",
    "    # Create class directories\n",
    "    os.makedirs(os.path.join(downsized_images_dir, class_name), exist_ok=True)\n",
    "\n",
    "    # Move image\n",
    "    shutil.copy(img_path, os.path.join(downsized_images_dir, class_name, img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsize test set to take 20% of original test set\n",
    "\n",
    "# Define paths\n",
    "parent_dir = './Wildlife_Animals_Split/images/test'\n",
    "\n",
    "# Collect all valid image paths\n",
    "image_files = []\n",
    "for class_name in os.listdir(parent_dir):\n",
    "    class_path = os.path.join(parent_dir, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "    for img_name in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        if img_path.lower().endswith(('jpg', 'jpeg', 'png')):\n",
    "            image_files.append(img_path)\n",
    "\n",
    "\n",
    "subset_size = int(0.2 * len(image_files))  # 20% of the original validation set\n",
    "selected_images = random.sample(image_files, subset_size)\n",
    "\n",
    "# Clear the existing train folder and downsized dataset folder\n",
    "downsized_images_dir = './Wildlife_Animals_Downsized/images/test'\n",
    "os.makedirs(downsized_images_dir, exist_ok=True)\n",
    "\n",
    "# Move selected images and their labels to downsized dataset\n",
    "for img_path in selected_images:\n",
    "    img_name = os.path.basename(img_path)\n",
    "    class_name = os.path.basename(os.path.dirname(img_path))\n",
    "\n",
    "    # Create class directories\n",
    "    os.makedirs(os.path.join(downsized_images_dir, class_name), exist_ok=True)\n",
    "\n",
    "    # Move image\n",
    "    shutil.copy(img_path, os.path.join(downsized_images_dir, class_name, img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories created successfully!\n"
     ]
    }
   ],
   "source": [
    "labels_dir = './Wildlife_Animals_Downsized/labels'\n",
    "os.makedirs(labels_dir, exist_ok=True)\n",
    "\n",
    "# create directories for labels\n",
    "\n",
    "# List of animal names\n",
    "animals = [\n",
    "    \"bald_eagle\", \"black_bear\", \"bobcat\", \"cheetah\", \"cougar\", \"deer\", \"elk\", \n",
    "    \"gray_fox\", \"Horse\", \"hyena\", \"lion\", \"raccoon\", \"red_fox\", \"rhino\", \"tiger\", \n",
    "    \"wolf\", \"zebra\"\n",
    "]\n",
    "\n",
    "# Define the base directory where the folders will be created\n",
    "labels_dir = './Wildlife_Animals_Downsized/labels'\n",
    "\n",
    "# Create the main directories for train, val, and test\n",
    "for folder in ['train', 'val', 'test']:\n",
    "    folder_path = os.path.join(labels_dir, folder)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    # Create subdirectories for each animal in train, val, and test folders\n",
    "    for animal in animals:\n",
    "        animal_folder = os.path.join(folder_path, animal)\n",
    "        if not os.path.exists(animal_folder):\n",
    "            os.makedirs(animal_folder)\n",
    "\n",
    "print(\"Directories created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting # of images after split and downsizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in original_train_folder set: 6836\n",
      "Number of images in original_val_folder set: 855\n",
      "Number of images in original_test_folder set: 857\n",
      "\n",
      "Number of images in downsized_train_folder set: 873\n",
      "Number of images in downsized_val_folder set: 161\n",
      "Number of images in downsized_test_folder set: 167\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_images_in_folders(dataset_folder):\n",
    "    # Initialize a counter for images\n",
    "    image_count = 0\n",
    "    \n",
    "    # Walk through the directory to count images in subfolders\n",
    "    for root, dirs, files in os.walk(dataset_folder):\n",
    "        for file in files:\n",
    "            # You can adjust the image file extensions based on your dataset (e.g., '.jpg', '.png')\n",
    "            if file.endswith('.jpg') or file.endswith('.png'):\n",
    "                image_count += 1\n",
    "    \n",
    "    return image_count\n",
    "\n",
    "# Paths to your validation and test sets\n",
    "original_train_folder = \"./Wildlife_Animals_Split/images/train\"\n",
    "original_val_folder = \"./Wildlife_Animals_Split/images/val\"\n",
    "original_test_folder = \"./Wildlife_Animals_Split/images/test\"\n",
    "\n",
    "downsized_train_folder = \"./Wildlife_Animals_Downsized/images/train\"\n",
    "downsized_val_folder = \"./Wildlife_Animals_Downsized/images/val\"\n",
    "downsized_test_folder = \"./Wildlife_Animals_Downsized/images/test\"\n",
    "\n",
    "# Count the images in each set\n",
    "train_image_count = count_images_in_folders(original_train_folder)\n",
    "val_image_count = count_images_in_folders(original_val_folder)\n",
    "test_image_count = count_images_in_folders(original_test_folder)\n",
    "\n",
    "downsized_train_folder_count = count_images_in_folders(downsized_train_folder)\n",
    "downsized_val_folder_count = count_images_in_folders(downsized_val_folder)\n",
    "downsized_test_folder_count = count_images_in_folders(downsized_test_folder)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Number of images in original_train_folder set: {train_image_count}\")\n",
    "print(f\"Number of images in original_val_folder set: {val_image_count}\")\n",
    "print(f\"Number of images in original_test_folder set: {test_image_count}\")\n",
    "\n",
    "print(f\"\\nNumber of images in downsized_train_folder set: {downsized_train_folder_count}\")\n",
    "print(f\"Number of images in downsized_val_folder set: {downsized_val_folder_count}\")\n",
    "print(f\"Number of images in downsized_test_folder set: {downsized_test_folder_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO NOT NEED TO RUN CODE ABOVE AS IT SPLITS AND DOWNSIZES DATA. Already have split and downsized data in GitHub\n",
    "## Start here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Created ground truth labels for Wildlife_Animals_Downsized. Placed in 'labels_dir'\n",
    "#### Use cell below to change the labels for .txt files in each animal folder\n",
    "Use .yaml file for the corresponding animal labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels updated.\n"
     ]
    }
   ],
   "source": [
    "# use this code to change the class label numbers to its respective label animal number\n",
    "# change the annotations_folder path to where you saved the txt files and change the mapping\n",
    "\n",
    "import os\n",
    "\n",
    "# Define the label mapping (old label -> new label)\n",
    "label_mapping = {\n",
    "    0: 11,  # Change '0' to '1'\n",
    "}\n",
    "\n",
    "# Path to your annotations folder\n",
    "annotations_folder = 'C:/Users/britn/CMPE258_Wildlife_Animals/Wildlife_Animals_Downsized/labels/train/raccoon'\n",
    "\n",
    "# Iterate through each annotation file\n",
    "for filename in os.listdir(annotations_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(annotations_folder, filename)\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        # Update the class label in each line\n",
    "        new_lines = []\n",
    "        for line in lines:\n",
    "            parts = line.split()\n",
    "            old_label = int(parts[0])\n",
    "            new_label = label_mapping.get(old_label, old_label)  # Get the new label, or keep old if not mapped\n",
    "            parts[0] = str(new_label)\n",
    "            new_lines.append(\" \".join(parts))\n",
    "        \n",
    "        # Save the updated lines\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.writelines(new_lines)\n",
    "\n",
    "print(\"Class labels updated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training YOLOv8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained YOLO model or a custom model\n",
    "model = YOLO(\"yolov8m.pt\")  # You can use a pre-trained model like yolov8m.pt\n",
    "\n",
    "downsized_yaml = './Wildlife_Animals_Downsized/dataset.yaml'\n",
    "# Directory where the annotated images will be saved\n",
    "output_dir = './Wildlife_Animals_Downsized/output_images/train'\n",
    "\n",
    "# Training\n",
    "try:\n",
    "    # Train the model on the bald eagle dataset\n",
    "    results = model.train(\n",
    "    data=downsized_yaml,\n",
    "    epochs=25,\n",
    "    imgsz=320,\n",
    "    batch=16,\n",
    "    lr0=0.001,\n",
    "    lrf=0.5,\n",
    "    save=True,\n",
    "    patience=5   # Early stopping patience: stop training if no improvement after 5 epochs\n",
    ")\n",
    "\n",
    "    print(\"Training completed successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Training failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access the trained model, run inference on the TRAINED DATA to save TRAIN annotated images and .txt files in directory\n",
    "TO:DO - after training, check the annotated images in output_images/train to see if the bounding boxes + labels are good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained YOLO model\n",
    "model = YOLO('C:/Users/britn/CMPE258FinalProject/runs/detect/train3/weights/best.pt')  # Path to the best trained model\n",
    "\n",
    "downsized_train_folder = \"./Wildlife_Animals_Downsized/images/train\"\n",
    "downsized_val_folder = \"./Wildlife_Animals_Downsized/images/val\"\n",
    "downsized_test_folder = \"./Wildlife_Animals_Downsized/images/test\"\n",
    "\n",
    "# Path to images\n",
    "train_images_dir = './Wildlife_Animals_Downsized/images/train'\n",
    "output_images_dir = './Wildlife_Animals_Downsized/output_images/train'\n",
    "output_labels_dir = './Wildlife_Animals_Downsized/output_labels/train'  # Directory to save .txt files\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_images_dir, exist_ok=True)\n",
    "os.makedirs(output_labels_dir, exist_ok=True)\n",
    "\n",
    "# Collect all image paths from the bald_eagle folder\n",
    "image_files = []\n",
    "for img_name in os.listdir(train_images_dir):\n",
    "    img_path = os.path.join(train_images_dir, img_name)\n",
    "    if img_path.lower().endswith(('jpg', 'jpeg', 'png')):  # Check if the file is an image\n",
    "        image_files.append(img_path)\n",
    "\n",
    "print(f\"Found {len(image_files)} images.\")\n",
    "\n",
    "# Run inference and save annotated images and .txt files\n",
    "for img_path in image_files:\n",
    "    img_name = os.path.basename(img_path)\n",
    "    print(f\"Running inference on {img_name}\")\n",
    "\n",
    "    # Run inference on the image\n",
    "    results = model(img_path)\n",
    "\n",
    "    # Ensure results is not a list before calling save\n",
    "    if isinstance(results, list):\n",
    "        results = results[0]  # YOLOv8 inference results are wrapped in a list, access the first item\n",
    "\n",
    "    # Save the annotated image\n",
    "    save_img_dir = os.path.join(output_images_dir, img_name)\n",
    "    results.save(save_img_dir)  # Saves to the output directory with bounding boxes and class labels\n",
    "\n",
    "    # Extract the bounding box details and save them as a .txt file\n",
    "    txt_file_path = os.path.join(output_labels_dir, img_name.replace('.jpg', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt'))\n",
    "\n",
    "    # Get the bounding boxes and class labels\n",
    "    labels = results.names  # Get class names (labels) from the model\n",
    "    boxes = results.boxes.xywh  # Get the box coordinates in x, y, width, height format\n",
    "    confs = results.boxes.conf  # Get the confidence scores\n",
    "    classes = results.boxes.cls  # Get the predicted class indices\n",
    "\n",
    "    with open(txt_file_path, 'w') as txt_file:\n",
    "        for i in range(len(boxes)):\n",
    "            # Write each detection as a line in the .txt file\n",
    "            class_id = int(classes[i])  # Convert class to integer ID\n",
    "            x_center, y_center, width, height = boxes[i]  # Bounding box values\n",
    "            conf = confs[i]  # Confidence score\n",
    "\n",
    "            # YOLO format: class_id x_center y_center width height (normalized)\n",
    "            txt_file.write(f\"{class_id} {x_center} {y_center} {width} {height} {conf}\\n\")\n",
    "\n",
    "    print(f\"Annotated image and .txt file saved for: {img_name}\")\n",
    "    print(f\"Saved to: {save_img_dir}\")\n",
    "    print(f\"Saved .txt to: {txt_file_path}\")\n",
    "    print(f\"Contents of image output directory: {os.listdir(output_images_dir)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After training, pass the VALIDATION DATA to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access the trained model, run inference on the VALIDATION DATA to save VAL annotated images and .txt files in directory\n",
    "TO-DO: Manually check the annotated images in output_images/val to see if the bounding boxes + labels are good\n",
    "    - If bounding boxes and labels are not good on val data, go back to hypertune the model then train again. *Make sure model is not fixated on training and val sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once model runs well for val dataset, check on test set (maybe)\n",
    "Note: using test set for the professor to run when assignment is turned in so not sure if it's a good idea to run the test set already. probably is though to double check the model is working well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
